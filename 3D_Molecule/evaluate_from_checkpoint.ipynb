{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961eec24",
   "metadata": {},
   "source": [
    "# Model Validation / Testing on OE62 from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8966deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csxuanli/miniconda3/envs/ocp-models/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging, load_config\n",
    "from ocpmodels.datasets import LmdbDataset\n",
    "from ocpmodels.common.registry import registry\n",
    "from ocpmodels.trainers import EnergyTrainer, ForcesTrainer\n",
    "\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60a6b6",
   "metadata": {},
   "source": [
    "### Define model variant by choosing a config file\n",
    "For each model, the following variants exist: **baseline**, **variant with Ewald message passing**, **increased cutoff** and **increased embedding size**.\n",
    "\n",
    "Configs to choose from: \n",
    "- schnet_oe62_baseline.yml\n",
    "- schnet_oe62_ewald.yml\n",
    "- schnet_oe62_cutoff.yml\n",
    "- schnet_oe62_embeddings.yml\n",
    "----------------------------\n",
    "- painn_oe62_baseline.yml\n",
    "- painn_oe62_ewald.yml\n",
    "- painn_oe62_cutoff.yml\n",
    "- painn_oe62_embeddings.yml\n",
    "----------------------------\n",
    "- dpp_oe62_baseline.yml\n",
    "- dpp_oe62_ewald.yml\n",
    "- dpp_oe62_cutoff.yml\n",
    "- dpp_oe62_embeddings.yml\n",
    "----------------------------\n",
    "- gemnet_oe62_baseline.yml\n",
    "- gemnet_oe62_ewald.yml\n",
    "- gemnet_oe62_cutoff.yml\n",
    "- gemnet_oe62_embeddings.yml\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7302e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"configs_oe62\"\n",
    "#-----------Put your model variant here-----------\n",
    "config_path = os.path.join(config_dir, \"dpp_oe62_baseline.yml\")\n",
    "\n",
    "# M -> 1000000\n",
    "\n",
    "# schnet_oe62_baseline.yml | 2.75M\n",
    "# schnet_oe62_ewald.yml | 12.21M\n",
    "# schnet_oe62_na.yml | 2.65M\n",
    "\n",
    "\n",
    "# painn_oe62_baseline.yml | 12.52M\n",
    "# painn_oe62_ewald.yml | 15.68M\n",
    "# painn_oe62_na.yml | 6.05M\n",
    "\n",
    "# dpp_oe62_baseline.yml | 2.76M\n",
    "# dpp_oe62_ewald.yml | 4.75M\n",
    "# dpp_oe62_na.yml | 1.97M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29e744",
   "metadata": {},
   "source": [
    "### Parse config file and initialize `EnergyTrainer` object for OE62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b378649d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: false\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2024-02-17-19-22-40-dpp_oe62_baseline\n",
      "  commit: d88d1d5\n",
      "  identifier: dpp_oe62_baseline\n",
      "  logs_dir: ./logs/tensorboard/2024-02-17-19-22-40-dpp_oe62_baseline\n",
      "  print_every: 5000\n",
      "  results_dir: ./results/2024-02-17-19-22-40-dpp_oe62_baseline\n",
      "  seed: 0\n",
      "  timestamp_id: 2024-02-17-19-22-40-dpp_oe62_baseline\n",
      "dataset:\n",
      "  normalize_labels: true\n",
      "  src: oe62/energy_linref_pbe0/train/pbe0_train.lmdb\n",
      "  target_mean: 0.0036029791066818145\n",
      "  target_std: 1.7420150967007746\n",
      "gpus: 1\n",
      "logger: tensorboard\n",
      "model: dimenetplusplus\n",
      "model_attributes:\n",
      "  cutoff: 6.0\n",
      "  hidden_channels: 256\n",
      "  max_neighbors: 50\n",
      "  num_after_skip: 2\n",
      "  num_before_skip: 1\n",
      "  num_blocks: 3\n",
      "  num_output_layers: 3\n",
      "  num_radial: 6\n",
      "  num_spherical: 7\n",
      "  otf_graph: true\n",
      "  out_emb_channels: 192\n",
      "  regress_forces: false\n",
      "  use_pbc: false\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 8\n",
      "  eval_batch_size: 32\n",
      "  eval_every: 10000\n",
      "  loss_energy: mae\n",
      "  lr_gamma: 0.1\n",
      "  lr_initial: 0.0001\n",
      "  lr_milestones:\n",
      "  - 750000\n",
      "  - 1125000\n",
      "  - 1500000\n",
      "  max_epochs: 250\n",
      "  num_workers: 2\n",
      "  warmup_factor: 0.2\n",
      "  warmup_steps: 250000\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: single_point_lmdb\n",
      "  description: Regressing to DFT total energies for structures in OE62\n",
      "  labels:\n",
      "  - DFT total energy\n",
      "  metric: mae\n",
      "  type: regression\n",
      "test_dataset:\n",
      "  src: oe62/energy_linref_pbe0/test/pbe0_test.lmdb\n",
      "trainer: energy\n",
      "val_dataset:\n",
      "  src: oe62/energy_linref_pbe0/val/pbe0_val.lmdb\n",
      "\n",
      "2024-02-17 19:22:56 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2024-02-17 19:22:56 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2024-02-17 19:22:56 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2024-02-17 19:22:56 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2024-02-17 19:22:56 (INFO): Loading dataset: single_point_lmdb\n",
      "2024-02-17 19:22:56 (INFO): Loading model: dimenetplusplus\n",
      "2024-02-17 19:23:04 (INFO): Loaded DimeNetPlusPlusWrap with 2755462 parameters.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "conf = load_config(config_path)[0]\n",
    "task = conf[\"fixed\"][\"task\"]\n",
    "model = conf[\"fixed\"][\"model\"]\n",
    "optimizer = conf[\"fixed\"][\"optimizer\"]\n",
    "name = conf[\"fixed\"][\"name\"]\n",
    "logger = conf[\"fixed\"][\"logger\"]\n",
    "dataset = conf[\"fixed\"][\"dataset\"]\n",
    "trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=name,\n",
    "    run_dir=\"./\",\n",
    "    is_debug=True,  # if True, do not save checkpoint, logs, or results\n",
    "    print_every=5000,\n",
    "    seed=0,  # random seed to use\n",
    "    logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False,  # whether to use PyTorch Automatic Mixed Precision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effffad1",
   "metadata": {},
   "source": [
    "### Load checkpoint file\n",
    "\n",
    "After training your model (using the provided `seml` commands, or the training notebook from this repository, paste the path to your checkpoint file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae65422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dir,\n",
    "    \"[your_checkpoint_dir]\",\n",
    "    \"best_checkpoint.pt\")\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4dfe5",
   "metadata": {},
   "source": [
    "### Validate or test model\n",
    "Replace the argument below by `split=\"val\"` to use the OE62 validation split instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7459b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.validate(split=\"test\")\n",
    "results = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"Results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45729cf",
   "metadata": {},
   "source": [
    "# Model Validation on OC20 from Checkpoint\n",
    "\n",
    "On OC20, only validation can be done locally. To generate results on the test set, follow the instructions on https://github.com/Open-Catalyst-Project/ocp to obtain files for submission on eval.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0261f",
   "metadata": {},
   "source": [
    "### Define model variant by choosing a config file\n",
    "For each model, the following variants exist: **baseline**, **variant with Ewald message passing**, **increased cutoff**.\n",
    "\n",
    "Configs to choose from: \n",
    "- schnet_oc20_baseline.yml\n",
    "- schnet_oc20_ewald.yml\n",
    "- schnet_oc20_cutoff.yml\n",
    "----------------------------\n",
    "- painn_oc20_baseline.yml\n",
    "- painn_oc20_ewald.yml\n",
    "- painn_oc20_cutoff.yml\n",
    "----------------------------\n",
    "- dpp_oc20_baseline.yml\n",
    "- dpp_oc20_ewald.yml\n",
    "- dpp_oc20_cutoff.yml\n",
    "----------------------------\n",
    "- gemnet_oc20_baseline.yml\n",
    "- gemnet_oc20_ewald.yml\n",
    "- gemnet_oc20_cutoff.yml\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37070ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"configs_oc20\"\n",
    "#-----------Put your model variant here-----------\n",
    "config_path = os.path.join(config_dir,\"schnet_oc20_baseline.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b05241",
   "metadata": {},
   "source": [
    "### Parse config file and initialize `ForcesTrainer` object for OC20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd710c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for split in [\"id\", \"ood_ads\", \"ood_cat\", \"ood_both\"]:\n",
    "    torch.cuda.empty_cache()\n",
    "    conf = load_config(config_path)[0]\n",
    "    task = conf[\"fixed\"][\"task\"]\n",
    "    model = conf[\"fixed\"][\"model\"]\n",
    "    optimizer = conf[\"fixed\"][\"optimizer\"]\n",
    "    name = conf[\"fixed\"][\"name\"]\n",
    "    logger = conf[\"fixed\"][\"logger\"]\n",
    "    # Replace dataset_train by dataset_id, dataset_ood_ads, dataset_ood_both or\n",
    "    # dataset_ood_cat to validate only on a particular subsplit (note that the\n",
    "    # validation set subsampling option is currently just available on the\n",
    "    # combination of all four splits, specified by putting dataset_train below)\n",
    "    dataset = conf[\"fixed\"][f\"dataset_{split}\"]\n",
    "    trainer = ForcesTrainer(\n",
    "        task=task,\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        optimizer=optimizer,\n",
    "        identifier=f\"{name}_{split}_test1\",\n",
    "        run_dir=\"./\",\n",
    "        is_debug=False,  # if True, do not save checkpoint, logs, or results\n",
    "        print_every=5000,\n",
    "        seed=0,  # random seed to use\n",
    "        logger=logger,  # logger of choice (tensorboard and wandb supported)\n",
    "        local_rank=0,\n",
    "        amp=False,  # whether to use PyTorch Automatic Mixed Precision\n",
    "    )\n",
    "    \n",
    "    trainer.train_dataset.close_db()\n",
    "    if trainer.config.get(\"val_dataset\", False):\n",
    "        trainer.val_dataset.close_db()\n",
    "    if trainer.config.get(\"test_dataset\", False):\n",
    "        trainer.test_dataset.close_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745ed49",
   "metadata": {},
   "source": [
    "### Load checkpoint file\n",
    "\n",
    "After training your model by using the provided `seml` commands, paste the path to your checkpoint file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9769edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dir,\n",
    "    \"[your_checkpoint_dir]\",\n",
    "    \"best_checkpoint.pt\")\n",
    "trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a855f57",
   "metadata": {},
   "source": [
    "### Validate model\n",
    "The setting below validates on a 1% subsample of all validation structures, drawn evenly from all four splits.\n",
    "Replace the argument below by `split=\"val\"` to use the full validation set (all four splits) instead (as this takes 100x as long, we recommend doing it overnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.validate(split=\"val_sub\") #put split=\"val\" for full validation set\n",
    "results = {key: val[\"metric\"] for key, val in metrics.items()}\n",
    "print(f\"Results for configuration {name}: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878898e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
